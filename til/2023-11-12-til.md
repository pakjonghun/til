---
date: 2023-11-12
category: til
---

## 개요

- 배포를 쉽게 하고 싶다.
- 하지만 아래의 기초적인 것들은 적용하고 싶다.
- 물론 내가 직접 한다는 것은 아니고 클라우드 서비스를 사용하면서 한다는 것이다 .ㅎ
- LoadBalance, Available Zone, CI/CD
- 이를 위해 여러가지 개념을 학습 중인데,
- 학습 하면 할 수록 평소에 궁금했던 용어의 개념을 알 수 있었고,
- 궁금했던 점이 해소되서 매우 좋았다.
- 아직 배울 것이 더 많지만 중간에 정리를 해 두는 것이 좋을 것 같다는 생각이 들어서
- 학습한 내용을 정리하고자 한다.
- 학습 내용은 인프런의 강좌를 듣고 반복해서 따라하는 식으로 진행하고 있다.

## 문제인식

- 간단하게 프론트 서버, 백서버를 만드는 부분까지는 어찌어찌 할 수 있을 것 같다.
- 하지만 DB 부분을 잘 모르는것도 문제지만
- 데브옵스쪽은 정말 더 모르는 것이 문제라고 생각해서
- 데브 옵스 쪽을 학습해야 겠다고 생각했다.
- 서비스를 사용자가 사용하는데
- 사용자가 몰리면 느려지거나, 서비스 업데이트 할때마다 DownTime 이 생기면 곤란하니까.
- 최소한의 기본적인 내용은 알고 적용해야 겠다는 생각이었다.
- fireBase, heroku, vercel 같은거 쓰면 알아서 해주지 않나? 생각 할 수도 있지만
- 아래 세가지 이유 때문에 결국 배워서 제대로 써 보기로 마음먹었다.
  - 서버리스의 한계(규모 확장에 불리하다는점, 소켓통신을 구현 할수 없다는점)
  - 편한 서비스는 제시하는 개념이 결국 aws에서 제공해주는 내용이라는점.
  - 편한 서비스는 비용이 비싸다는점.
  - 너무 데브옵스에 대해서 모르고, 사용하고 있다는 무지성.

## 가상서버

- 말 그대로 가상의 서버다. 물리적인 것이 아닌 소프트웨어적인 서버이고
- 흔히 말하는 클라우드의 VM(가상서버)라고 할 수 있다.

## 클러스터

- 가상서버는 여러개의 CPU(process) 라고 이해 할 수도 있다.
- 특히 nodejs 같은 경우 싱글 쓰레드 특징이 있으므로 더욱 더 클러스터를 CPU 하나가 동작 시킬 수 있는 서버 정도로 볼 수 있는데.
- 클러스터란 이런 의미에서 cpu 1개가 감당 할 수 있는 부분적인 서버 정도로 볼 수 있다.
- pm2 같은 툴을 이용해서 한개의 가상 서버를 클러스터를 나누어 사용 할 수 있다.

## CI/CD

- CI 는
  - 지속적인 통합 이라는 뜻으로
  - 코드 푸시 -> 테스팅 -> 기타 컨펌 -> 서비스 브랜치에 머지 등 프로세서를 자동으로 처리하는 것을 의미한다.
  - 깃 액션으로 쉽게 구현 할 수 있고, 조금 복잡하고 어려운 부분은 이미 git market 에 구현이 되 있어서 찾아서 쓰면된다.
- CD 지속적인 배포라는 뜻으로 는 조금 더 들어간다.
  - 깃헙 앱션에서 배포 전의 단계를 모두 했으면,
  - 서버에 접근해서 서버에서 해야 할 일을 cli 명령으로 자동 실행하게 하는
  - 스크립트를 짜야 한다.
  - 역시 git action 으로 구현 할 수 있다.
- 환경변수
  - 개인적인 정보, 민감한 정보인 내용은
  - 환경변수로 만들어서 별도로 관리 해야 하는데
  - 백앤드 서버 프론트 서버에도 적용되지만
  - 깃헙 액션에도 적용 해야 한다.

```
name: deploy

on:
  push:
    branches:
      - master

jobs:
  test:
    runs-on: ubuntu-22.04
    steps:
      - name: checkout
        uses: actions/checkout@v4
      - name: node setup
        uses: actions/setup-node@v3
        with:
          node-version: 18.x
      - name: install npm packages
        run: npm ci
      - name: install and run redis server
        run: |
          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/redis.list
          sudo apt-get update
          sudo apt-get install redis
          redis-server --daemonize yes --requirepass password --port 6380

      - name: run test
        run: npm run test
      - name: build
        run: npm run build

  deploy:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: keypair set
        run: |
          mkdir -p ~/.ssh
          echo "${{secrets.SSH_PRIVATE_KEY}}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: host set
        run: |
          echo "${{secrets.SSH_CONFIRM_HOST}}" >> ~/.ssh/known_hosts
          chmod 644 ~/.ssh/known_hosts

      - name: deploy
        run: |
          ssh ${{secrets.SSH_HOST_NAME}}@${{secrets.SSH_STATIC_IP}} "
          cd mobile_card_backend
          git pull || exit -1
          npm run build || exit -1
          sudo pkill node
          npm start & npx wait-on http://localhost:4000/messages || exit -1
          exit
          "

```

## 인증 보안

- RSA 를 통한 키페어 방식의 확인 을 통해서 여러 보안상 잇점을 얻을 수 있다.
- 보통 SSH로 접근 할때 이 방식을 사용하는데 접근 하는쪽에서
- private key 를 보내고 받는쪽에서 public key 로 확인하는 과정을 거친다.
- 내가 사용하는 기계(머신, 컴퓨터) 에서 생성한 키 쌍을 미리 리모트 서버에 입력 해 둬서
- 어떤 키를 노출 시키지 않고 쉽게 접속 하는 프로세서를 만들 수도 있다.

## 스케일링

- 스케일링이란 부하를 분산할 가상머신을 더 좋은 머신으로 업그레이드 하거나 여러개를 다시 생성해서 로드밸런서에 연결하는 것을 말한다.
- 스케일링을 통해서 더 안정적인 서버운영을 할 수 있다.
- 보통 스케일링은 안정성과 비용적인 측면 때문에 수평확장을 많이 한다. 좋은 서버 1대 보다는 중간 서버 2대가 더 낫다는 말임.
- 번외로 로드밸런서는 비용이 비싸다(이 로드벨런서는 비싸다, AZ도 되어 있고, 로드벨런서가 죽지 않게 여러모로 신경 많이 써 두었기 때문이다.)

## PM2

- 노드 환경에서 해당 VM 의 리소스를 모두 활용 할 수 있게 해주는 툴이다.
- NGINX 같은 서버에서도 적용 할 수 있는 부분이지만
- 작은 서비스 에서는 굳이 NGINX 는 오버스펙 이므로
- PM2 를 사용하게 되는 것 같다.
- CD 를 할때(무중단 배포) 알아서 살아있는 클러스터를 유지하면서 하나씩 배포 한다는 점에서
- 다운타임없이 배포를 이어서 할 수 있다.

## 로드 밸런서

- 말 그대로 로드(부담) 밸런서(분산) 이다.
- 무거운 작업요청이 많이 들어오면 이 요청을
- 여유가 있는 VM 에 자동으로 분산 시켜서 요청 해서 빠른 처리를 할 수 있게 한다.
- AWS 에서 이것은 로드밸런서에 달아둔 VM 으로 알아서 부하분산이 되는 식이다.
- 스케일링을 할때에도 껏다가 켜서 다운타임이 발생하는 것이 아닌
- 잘 작동하는 서버를 남겨두고 하나씩 추가하는 식으로 작동하므로 매우 좋다.
- HTTPS 를 적용하기 쉽다는 점은 보너스!!
- 적용 방법은
  - 일단 VM 하나를 열심히 세팅한다.
  - 그리고 스냅샷 하나를 찍어둔다 찰칵!
  - 스냅샷에서 동일한 환경조건의 머신을 다시 만들고
  - 이 머신의 인바운드를 다시 설정 해주면 끝
  - 수동으로 수평확장을 할 수 있다.

## 기타

- 리눅스 명령
  - ~ 는 루트 경로를 나타내는 축약어
  - cat은 파일 내용을 볼 수 있는 명령어 cat ~/.ssh/rsa_id
  - echo 는 파일 내용을 출력하는 명령어 echo ~/.ssh/rsa_id
  - chmod 는 파일 접근 권한을 설정해 주는 명령어 접근 권한 은 크게 3개 chmod 644(1,2,3) ~/.ssh/rsa_id
  - ">" 는 upsert 하라는 명령어 echo ~/.ssh/rsa_id > ~/save/rsa_id
  - ">>" 는 append 하라는 명령어 echo ~/.ssh/rsa_id >> ~/save/rsa_id
  - ssh 관련
    - ssh -T githubAction 은 대화형 터미널이 아니므로 T 옵션을 붙인다.
    - ssh-keygen -t rsa -b 4096 -C "alias name" rsa 키를 4096 용량으로(클수록 복잡도 증가) alias 로 저장한다.
    - ssh-keygen -t rsa -b 4096 -C "alias name" -f ~/.ssh/alias_rsa 키를 4096 용량으로(클수록 복잡도 증가) alias 로 저장하고 파일은 alias_rsa로 한다.
    - ssh-keyscan ip주소 호스트 키 를 모두 불러올 수 있다(사전에 접속 해야함)
